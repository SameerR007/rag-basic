{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data into database\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = TextLoader(\"tweets.txt\")\n",
    "database=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'tweets.txt'}, page_content='\"Words are beautiful, but action is supreme.\"\\n\\n\"Murphy\\'s law doesn\\'t mean that something bad will happen. It means that whatever can happen, will happen.\"\\n- Cooper\\n\\nKids, donâ€™t take up sport. Take up baking or something. Die at 60 really fat and happy.\\n\\nNever sit in a class full of mathematicians.\\n\\nOne day everything will become meaningless.\\n\\nIt is easier to persuade people in debates than in discussions.')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the databse into chunks where each chunk contains a tweet\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=1,\n",
    "    chunk_overlap=0,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 45, which is longer than the specified 1\n",
      "Created a chunk of size 116, which is longer than the specified 1\n",
      "Created a chunk of size 89, which is longer than the specified 1\n",
      "Created a chunk of size 44, which is longer than the specified 1\n",
      "Created a chunk of size 43, which is longer than the specified 1\n"
     ]
    }
   ],
   "source": [
    "with open(\"tweets.txt\") as f:\n",
    "    data = f.read()\n",
    "chunks = text_splitter.create_documents([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='\"Words are beautiful, but action is supreme.\"'),\n",
       " Document(page_content='\"Murphy\\'s law doesn\\'t mean that something bad will happen. It means that whatever can happen, will happen.\"\\n- Cooper'),\n",
       " Document(page_content='Kids, donâ€™t take up sport. Take up baking or something. Die at 60 really fat and happy.'),\n",
       " Document(page_content='Never sit in a class full of mathematicians.'),\n",
       " Document(page_content='One day everything will become meaningless.'),\n",
       " Document(page_content='It is easier to persuade people in debates than in discussions.')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#creating embeddings for the chunks in data base\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = hf.embed_query(\"hi this is harrison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hf.embed_documents([\"hi this is harrison\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Words are beautiful, but action is supreme.\"'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hf.embed_documents([chunks[0].page_content])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing chunks as embeddings in vector database\n",
    "from langchain_community.vectorstores import FAISS\n",
    "db = FAISS.from_documents(chunks,hf )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Kids, donâ€™t take up sport. Take up baking or something. Die at 60 really fat and happy.'),\n",
       " Document(page_content='\"Words are beautiful, but action is supreme.\"'),\n",
       " Document(page_content='It is easier to persuade people in debates than in discussions.'),\n",
       " Document(page_content='One day everything will become meaningless.')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Tennis match\"\n",
    "docs = db.similarity_search(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing retriever to directly get the similar chunks related to query\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.invoke(\"Tennis match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Kids, donâ€™t take up sport. Take up baking or something. Die at 60 really fat and happy.'),\n",
       " Document(page_content='\"Words are beautiful, but action is supreme.\"'),\n",
       " Document(page_content='It is easier to persuade people in debates than in discussions.'),\n",
       " Document(page_content='One day everything will become meaningless.')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating model for llm that need to be used for getting final prompt (user query + similar document) \n",
    "from langchain_huggingface.llms import HuggingFacePipeline\n",
    "\n",
    "hf = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"gpt2\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs={\"max_new_tokens\": 10},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"how are you?\\n\\nI'm actually very happy that I'm\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf.invoke(\"how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"tennis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'tennis',\n",
       " 'context': [Document(page_content='Kids, donâ€™t take up sport. Take up baking or something. Die at 60 really fat and happy.'),\n",
       "  Document(page_content='\"Words are beautiful, but action is supreme.\"'),\n",
       "  Document(page_content='Never sit in a class full of mathematicians.'),\n",
       "  Document(page_content='One day everything will become meaningless.')],\n",
       " 'answer': 'System: The given context is a set of tweets. You have to return one of the tweets that matches the most with the given user input and explain it in context with the user inputContext: Kids, donâ€™t take up sport. Take up baking or something. Die at 60 really fat and happy.\\n\\n\"Words are beautiful, but action is supreme.\"\\n\\nNever sit in a class full of mathematicians.\\n\\nOne day everything will become meaningless.\\nHuman: tennis player, you\\'re just a young basketball player.'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "llm = hf\n",
    "system_prompt = (\n",
    "    \"The given context is a set of tweets. You have to return one of the tweets that matches the most with the given user input and explain it in context with the user input\"\n",
    "    \"Context: {context}\"\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "chain.invoke({\"input\": query})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
